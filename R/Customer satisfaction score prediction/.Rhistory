fit=glm(Class~.,data=cd_train,family = 'binomial')
fit
sort(vif(fit),decreasing = T)
library(car)
library(car)
sort(vif(fit),decreasing = T)
fit=glm(Class~.-Amount,data=cd_train,family = 'binomial')
sort(vif(fit),decreasing = T)
fit=glm(Class~.-Amount-V16,data=cd_train,family = 'binomial')
sort(vif(fit),decreasing = T)
fit=glm(Class~.-Amount-V16-V10,data=cd_train,family = 'binomial')
sort(vif(fit),decreasing = T)
fit=step(fit)
gc()
gc()
gc()
summary(fit)
formula(fit)
fit=glm(Class ~ V4 + V6 + V8 + V9 + V11 + V12 + V13 + V14 + V15 + V17 +
V21 + V22 + V23,data=cd_train,family = 'binomial')
test.score=predict(fit,newdata = cd_test,type='response')
test.score
pROC::roc(cd_test$Class,test.score)
cutoffs=seq(0.001,0.999,0.001)
cutoff_data=data.frame(cutoff=99,KS=99)
real=cd_test$Class
real=cd_train$Class
train.score=predict(fit,newdata = cd_train,type='response')
for(cutoff in cutoffs){
predicted=as.numeric(train.score>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=TN+FP
KS=(TP/P)-(FP/N)
cutoff_data=rbind(cutoff_data,c(cutoff,KS))
}
cutoff_data=cutoff_data[-1,]
View(cutoff_data)
which.max(cutoff_data$KS)
final_cutoff= cutoff_data$cutoff[which.max(cutoff_data$KS)]
final_cutoff
test.hardclass.scores=as.numeric(test.score>final_cutoff)
table(cd_test$Class,test.hardclass.scores)
GFG <- data.frame(
Category  = c ("A","B","C","B","C","A","C","A","B"),
Frequency= c(9,5,0,2,7,8,1,3,7)
GFG = data.frame(
Category  = c ("A","B","C","B","C","A","C","A","B"),
Frequency= c(9,5,0,2,7,8,1,3,7)
GFG = data.frame(
Category  = c ("A","B","C","B","C","A","C","A","B"),
Frequency= c(9,5,0,2,7,8,1,3,7)
GFG
GFG = data.frame(
Category  = c("A","B","C","B","C","A","C","A","B"),
Frequency= c(9,5,0,2,7,8,1,3,7)
GFG = data.frame(
Category  = c("A","B","C","B","C","A","C","A","B"),
Frequency= c(9,5,0,2,7,8,1,3,7)
)
GFG = data.frame(
Category  = c("A","B","C","B","C","A","C","A","B"),
Frequency= c(9,5,0,2,7,8,1,3,7)
)
rm(Frequency)
library(dplyr)
View(GFG)
GFG%>%group_by(Category)
GFG%>%group_by(Category)%>%mean()
GFG%>%group_by(Category)%>%mutate(Frequency=mean(Frequency))
library(cvTools)
library(tree)
library(randomForest)
library(dplyr)
library(car)
library(read.table)
setwd('D:/EDVANCER/R/Project 5')
library(fread)
library('read.table')
bank-full_test=fread('bank-full_test.csv')
?read.table
?fread
??fread
bank-full_test=fread('bank-full_test.csv')
library(data.table)
bank-full_test=fread('bank-full_test.csv')
setwd('D:/EDVANCER/R/Project 5')
bank-full_test=fread('bank-full_test.csv')
bank-full_test=fread('bank-full_test.csv')
bank-full_test=fread('bank-full_test')
bank-full_test=fread('bank-full_test.csv')
bank-full_test=fread(file = 'bank-full_test.csv')
bank-full_test=fread(file = 'bank-full_test.csv')
bank-full_test=fread(file = "bank-full_test.csv")
bank-full_test=fread(file = "bank_full_test.csv")
bank-full_test=fread(input = "bank-full_test.csv")
bank-full_test=data.frame(fread("bank-full_test.csv"))
bank-full_test=data.frame(fread("bank_full_test.csv"))
setwd('D:/EDVANCER/R/Project 5')
bank-full_test=data.frame(fread("bank_full_test.csv"))
data.frame(fread("bank_full_test.csv"))
bf_test=data.frame(fread("bank_full_test.csv"))
bf_train=data.frame(fread("bank_full_train.csv"))
View(bf_train)
View(bf_test)
bf_train$data='train'    #add new col for identifying train data
bf_test$data='test'      #add new col for identifying test data
bf_test$y=NA
bf_all=rbind(bf_train,bf_test)
View(bf_all)
glimpse(bf_all)
sapply(bf_all,function(x) sum(is.na(x)))
bf_all=bf_all%>%
select(-ID)
glimpse(bf_all)
table(bf_all$pdays)
table(bf_all$previous)
bf_all%>%
mutate(pdays_-1=ifelse(pdays==-1))
bf_all%>%
mutate(pdays_1=ifelse(pdays==-1))
bf_all%>%
mutate(pdays_1=ifelse(pdays==-1,1,0))
bf_all=bf_all%>%
mutate(pdays_1=ifelse(pdays==-1,1,0))
glimpse(bf_all)
table(bf_all$previous)
bf_all%>%
mutate(previous_0=ifelse(previous==0,1,0))
bf_all=bf_all%>%
mutate(previous_0=ifelse(previous==0,1,0))
table(bf_all$pdays,bf_all$previous)
bf_all=bf_all%>%
select(-pdays,-previous)
glimpse(bf_all)
colnames(bf_all)
colnames(bf_all)[1]
class(colnames(bf_all)[1])
cat_cols=c('job','marital','education','default','housing','loan','contact','month','poutcome')
CreateDummies=function(data,var,freq_cutoff=0){     #create dummies func
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for(cat in categories){
name=paste(var,cat,sep='_')
name=gsub(" ",'',name)
name=gsub('-','_',name)
name=gsub('\\?','Q',name)
name=gsub('<','LT_',name)
name=gsub('\\+','',name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
table(bf_all$job)
table(bf_all$job)
table(bf_all$marital)
table(bf_all$education)
table(bf_all$default)
table(bf_all$housing)
table(bf_all$loan)
table(bf_all$contact)
table(bf_all$month)
table(bf_all$poutcome)
cat_cols
cat_cols[1]
i in cat_cols[i]
cat_cols.length
for(cat in cat_cols){
bf_all=CreateDummies(bf_all,cat,100)
}
bf_all$y=as.numeric(ifelse(y=='yes',1,0))
bf_all$y=as.numeric(ifelse(bf_all$y=='yes',1,0))
glimpse(bf_all)
bf_all$y=as.factor(bf_all$y)
glimpse(bf_all)
bf_train=bf_all%>%
filter(data=='train')%>%
select(-data)
bf_test=bf_all%>%
filter(data=='test')%>%
select(-data)
s=sample(nrow(bf_train),0.7*nrow(bf_train))
bf_train1=bf_train[s,]
bf_train2=bf_train[-s,]
lfit=lm(y~.,data = bf_train1)      #applying train1 for vif
sort(vif(lfit),decreasing = T)
summary(lfit)
lfit=lm(y~.,data = bf_train1)
bf_all$y=as.numeric(ifelse(bf_all$y=='yes',1,0))
glimpse(bf_all)
bf_train=bf_all%>%
filter(data=='train')%>%
select(-data)
bf_test=bf_all%>%
filter(data=='test')%>%
select(-data)
s=sample(nrow(bf_train),0.7*nrow(bf_train))   #sampling our train data in 70-30 ratio
bf_train1=bf_train[s,]
bf_train2=bf_train[-s,]
lfit=lm(y~.,data = bf_train1)      #applying train1 for vif
sort(vif(lfit),decreasing = T)
summary(lfit)
setwd('D:/EDVANCER/R/Project 5')
library(data.table)
bf_test=data.frame(fread("bank_full_test.csv"))
bf_train=data.frame(fread("bank_full_train.csv"))
View(bf_train)
View(bf_test)
bf_train$data='train'    #add new col for identifying train data
bf_test$data='test'      #add new col for identifying test data
bf_test$y=NA
bf_all=rbind(bf_train,bf_test)   #combining both train and test in single dataset
View(bf_all)
glimpse(bf_all)
sapply(bf_all,function(x) sum(is.na(x)))
bf_all=bf_all%>%
select(-ID)
glimpse(bf_all)
bf_all=bf_all%>%
mutate(pdays_1=ifelse(pdays==-1,1,0))
bf_all=bf_all%>%
mutate(previous_0=ifelse(previous==0,1,0))
bf_all=bf_all%>%
select(-pdays,-previous)
glimpse(bf_all)
cat_cols=c('job','marital','education','default','housing','loan','contact','month','poutcome')  #store all cat cols in single variable
CreateDummies=function(data,var,freq_cutoff=0){     #create dummies func
t=table(data[,var])
t=t[t>freq_cutoff]
t=sort(t)
categories=names(t)[-1]
for(cat in categories){
name=paste(var,cat,sep='_')
name=gsub(" ",'',name)
name=gsub('-','_',name)
name=gsub('\\?','Q',name)
name=gsub('<','LT_',name)
name=gsub('\\+','',name)
data[,name]=as.numeric(data[,var]==cat)
}
data[,var]=NULL
return(data)
}
#checking all cat cols for diff categories
table(bf_all$job)
table(bf_all$marital)
table(bf_all$education)
table(bf_all$default)
table(bf_all$housing)
table(bf_all$loan)
table(bf_all$contact)
table(bf_all$month)
table(bf_all$poutcome)
cat_cols
for(cat in cat_cols){
bf_all=CreateDummies(bf_all,cat,100)
}
bf_all$y=as.numeric(bf_all$y=='yes')   #converting y into 0 and 1
glimpse(bf_all)
bf_train=bf_all%>%
filter(data=='train')%>%
select(-data)
bf_test=bf_all%>%
filter(data=='test')%>%
select(-data)
s=sample(nrow(bf_train),0.7*nrow(bf_train))   #sampling our train data in 70-30 ratio
bf_train1=bf_train[s,]
bf_train2=bf_train[-s,]
lfit=lm(y~.,data = bf_train1)
summary(lfit)
sort(vif(lfit),decreasing = T)
lfit=lm(y~.-previous_0,data = bf_train1)
sort(vif(lfit),decreasing = T)
lfit=lm(y~.-previous_0-poutcome_unknown,data = bf_train1)
sort(vif(lfit),decreasing = T)
lfit=lm(y~.-previous_0-poutcome_unknown-month_may,data = bf_train1)
sort(vif(lfit),decreasing = T)
lfit=lm(y~.-previous_0-poutcome_unknown-month_may-job_blue_collar,data = bf_train1)
sort(vif(lfit),decreasing = T)
log_lfit=step(lfit)
lfit=glm(y~.-previous_0-poutcome_unknown-month_may-job_blue_collar,data = bf_train1,family='binomial')  #running logistic regression
log_lfit=step(lfit)
formula(log_lfit)
train1.log.model=glm(log_lfit,data = bf_train1,family = 'binomial')
train1.log.model
library(pROC)
train2.prob.scores=predict(train1.log.model,data=bf_train2,type = 'response')
roc(train2.prob.scores,train2$y)
roc(train2.prob.scores,bf_train2$y)
roc(bf_train2$y,train2.prob.scores)
train2.prob.scores=predict(train1.log.model,data=bf_train2,type = 'response')
formula(log_lfit)
train1.log.model=glm(y ~ balance + day + duration + campaign + pdays_1 + job_student +
job_housemaid + job_retired + job_admin. + job_management +
marital_married + education_primary + housing_yes + loan_no +
contact_unknown + contact_cellular + month_mar + month_sep +
month_oct + month_jan + month_apr + month_nov + month_jun +
month_aug + month_jul + poutcome_other + poutcome_failure,data = bf_train1,family = 'binomial')   #build final model on train1
train2.prob.scores=predict(train1.log.model,data=bf_train2,type = 'response')
train2.prob.scores=predict(train1.log.model,data=bf_train2,type = 'response')
train2.prob.scores=predict(train1.log.model,newdata=bf_train2,type = 'response')
roc(bf_train2$y,train2.prob.scores)
roc(bf_train2$y,train2.prob.scores)$auc
train2.prob.scores
train.log.model=glm(y ~ balance + day + duration + campaign + pdays_1 + job_student +
job_housemaid + job_retired + job_admin. + job_management +
marital_married + education_primary + housing_yes + loan_no +
contact_unknown + contact_cellular + month_mar + month_sep +
month_oct + month_jan + month_apr + month_nov + month_jun +
month_aug + month_jul + poutcome_other + poutcome_failure,data = bf_train,family = 'binomial')   #build final model on train
View(train.log.model)
test.prob.scores=predict(train.log.model,newdata=bf_test,type = 'response')
test.prob.scores
train.prob.scores=predict(train.log.model,newdata=bf_train,type = 'response')
real=bf_train$y
cutoffs=seq(0.001,0.999,0.001)
cutoff_data=data.frame(cutoff=99,KS=99)
#for loop for various formulae calculations
for(cutoff in cutoffs){
predicted=as.numeric(train.score>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=FP+TN
KS=(TP/P)-(FP/N)
cutoff_data=rbind(cutoff_data,c(cutoff,KS))
}
View(cutoff_data)
cutoff_data=cutoff_data[-1,]
#for loop for various formulae calculations
for(cutoff in cutoffs){
predicted=as.numeric(train.prob.scores>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=FP+TN
KS=(TP/P)-(FP/N)
cutoff_data=rbind(cutoff_data,c(cutoff,KS))
}
View(cutoff_data)
cutoff_data=cutoff_data[-1,]
cutoffs=seq(0.001,0.999,0.001)
cutoff_data=data.frame(cutoff=99,KS=99)
#for loop for various formulae calculations
for(cutoff in cutoffs){
predicted=as.numeric(train.prob.scores>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=FP+TN
KS=(TP/P)-(FP/N)
cutoff_data=rbind(cutoff_data,c(cutoff,KS))
}
View(cutoff_data)
cutoff_data=cutoff_data[-1,]
which.max(cutoff_data$KS)
cutoff_data$cutoff[which.max(cutoff_data$KS)]
final_cutoff=cutoff_data$cutoff[which.max(cutoff_data$KS)]
test.hardclass.scores=as.numeric(test.prob.scores>final_cutoff)
test.hardclass.scores
table(test.hardclass.scores)
bf_train_data=bd_all%>%
filter(data=='train')
bf_train_data=bf_all%>%
filter(data=='train')
mean(bf_train_data$age)
round(mean(bf_train_data$age),2)
var(bf_train_data$balance)
var(bf_all$balance)
table(bf_train_data$y)
prop.table(bf_train_data$y)
sum(prop.table(bf_train_data$y))
table(bf_train_data$y)
sum(bf_train_data$y==1)/nrow(bf_train_data)
sum(bf_train_data$y==1)/nrow(bf_train_data)
sum(bf_train_data$y==0)/nrow(bf_train_data)
setwd('D:/EDVANCER/R/Project 5')
q()
library(cvTools)
library(randomForest)
final_cutoff
which.max(cutoff_data$KS
which.max(cutoff_data$KS)
bf_train$y=as.factor(bf_train$y)
library(dplyr)
glimpse(bf_train)
param=list(mtry=c(5,10,20),
ntree=c(100,200,500),
maxnodes=c(5,10,20),
nodesize=c(1,2,5))
para_subset=function(param_list,n=10){
exp_grid=expand.grid(param_list)
s=sample(nrow(exp_grid),n)
param_sub=exp_grid[s,]
return(param_sub)
}
num_trials=10
subset_para=para_subset(param,num_trials)
subset_para
auc_func=function(y,yhat){
roccurve=pROC::roc(y,yhat)
aucscore=pROC::auc(roccurve)
return(aucscore)
}
myauc=0
for(i in 1:num_trials){
print(paste0('Starting iteration',i))
current_para=subset_para[i,]
k=cvTuning(randomForest,
y~.,
data=bf_train,
folds=cvFolds(nrow(bf_train),K=5,type = 'random'),
tuning=current_para,
seed=2,
cost = auc_func,
predictArgs = list(type='prob')
)
score.this=k$cv[,2]
if(score.this>myauc){
print(current_para)
myauc=score.this
print(score.this)
best_para=current_para
}
print('DONE')
}
myauc
best_para
best_para=as.data.frame(best_para)
View(best_para)
train.rf.model=randomForest(y~.,
data=bf_train,
mtry=best_para$mtry,
ntree=best_para$ntree,
maxnodes=best_para$maxnodes,
nodesize=best_para$nodesize)
test.prob.scores=predict(train.rf.model,newdata = bf_test,type='prob')
test.prob.scores
test.prob.scores=predict(train.rf.model,newdata = bf_test,type='prob')[,1]
test.prob.scores
test.prob.scores=predict(train.rf.model,newdata = bf_test,type='prob')[,2]
test.prob.scores
table(test.prob.scores)
train.prob.scores=predict(train.rf.model,newdata = bf_train,type='prob')[,2]
real=bf_train$y
cutoffs=seq(0.001,0.999,0.001)
cutoff_data=data.frame(cutoff=99,KS=99)
#for loop for various formulae calculations
for(cutoff in cutoffs){
predicted=as.numeric(train.prob.scores>cutoff)
TP=sum(real==1 & predicted==1)
TN=sum(real==0 & predicted==0)
FP=sum(real==0 & predicted==1)
FN=sum(real==1 & predicted==0)
P=TP+FN
N=FP+TN
KS=(TP/P)-(FP/N)
cutoff_data=rbind(cutoff_data,c(cutoff,KS))
}
View(cutoff_data)
cutoff_data=cutoff_data[-1,]
which.max[cutoff_data$KS]
which.max(cutoff_data$KS)
cutoff_data$cutoff[which.max(cutoff_data$KS)]
final_cutoff=cutoff_data$cutoff[which.max(cutoff_data$KS)]
final_cutoff
test.hardclass.scores=as.numeric(test.prob.scores>final_cutoff)
test.hardclass.scores
table(test.hardclass.scores)
getwd()
sum(is.na(test.hardclass.scores))
write.table(test.hardclass.scores,file='Sayen_Das_P5_part2.csv',col.names = 'y')
write.table(test.hardclass.scores,file='Sayen_Das_P5_part2.csv',col.names = 'y',row.names = F)
sum(1,2,3,4,5)
mean(as.factor(c(1, 1, 2, 3, 2, 1, 2, 3)))
a=1:6
b=1:4
a*b
0.4+0.4==0.8
var()
obj()
is()
sum(c('a','b'))
mean(c('a','b'))
min(c(‘a’, ‘b’, ‘c’, 100))
df <- list(df1 = data.frame('x' = c(1, 2, 3, 4), 'y'= c(4, 5, 5, 6)),
df2 = data.frame('y' = c(1, 2)))
colSums(df)
apply(df,1,colSums)
lapply(df,colSums)
0/0
1/0
v <- c(1, 2, FALSE, 3, TRUE, TRUE, FALSE)
sum(v)
test.hardclass.scores
test.hardclassyon.scores=ifelse(test.hardclass.scores==1,'yes','no')
test.hardclassyon.scores
write.table(test.hardclassyon.scores,file='Sayen_Das_P5_part2.csv',col.names = 'y',row.names = F)
table(test.hardclassyon.scores)
table(test.hardclass.scores)
